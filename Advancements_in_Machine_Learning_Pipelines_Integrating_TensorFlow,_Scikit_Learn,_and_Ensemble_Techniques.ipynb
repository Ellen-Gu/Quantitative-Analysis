{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN20thrxrSx7i7LTFofFQeH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ellen-Gu/Quantitative-Analysis/blob/main/Advancements_in_Machine_Learning_Pipelines_Integrating_TensorFlow%2C_Scikit_Learn%2C_and_Ensemble_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_zxOrWiPxTJ"
      },
      "outputs": [],
      "source": [
        "pip install mlflow   # this is for playing with databricks's mlflow module (as in Appendex 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras[tensorflow]   # this is for making tensorflow nn to be a sklearn compatible classifier, hence then it can be blended into the sklearn pipeline with other 8 classifiers."
      ],
      "metadata": {
        "id": "mr8Ruy_cQAtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import piles of modules, just like what R does: loading in piles of libraries in the head of R codes."
      ],
      "metadata": {
        "id": "AkjBorxN1NSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier  #this has been migrated to the following\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor  #pip install scikeras[tensorflow]\n",
        "\n",
        "# Surpress sklearn's package's version, use only after carefully checked the warnings in the first run\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='sklearn')  #surpress FutureWarning, not UserWarning\n",
        "# warnings.resetwarnings()  #--use this to reactive sklearn version warning\n"
      ],
      "metadata": {
        "id": "IlnY4hD3QAxE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recently I read some articles about ML ensembling methods.I think the hands-on book have all the contents of that article well covered. The hand-on book is one of my favorate book, and the chapter of ensembling is well illustrate sklearn's model emsemblings. One of the aspect that most ML books fail to mentioned is finacal viewpoint of model evalutations. That is well explained in another book (illustrating data analysis using both python and R ) which I like most. Almost all the books do not contains real world implementating part. Maybe that is only avaiable in real world, gaining from hands on experiences.\n",
        "\n",
        "To consolidating my learnings, some time has to be spent on codings. Nowdays openai can provide \"building blocks\" to releive some programming works, but people still need to learn programming to better communicate with computers. I have no concerns about the mathematics and computing aspects of ML/DL, but to coding well is another aspect, it needs lots of practice. I spend a well portion of time purely on learing coding itself, and also often \"talk\" with openai, aiming to integrate openai into my toolbox to speed up in ML/DL world. With many new modules/library emerging from time to time, people have to keep learning, and find ways to speed up and extend reachable fields.\n",
        "\n",
        "Fortunately, the data titanic is a data in python module OpenML. So I can happily load it in directly. After fetching data, it is a routine work to do EDA, data cleaning, imputing, feature selection... Those are tons of work before data can be used to modelings. Also, data works shed lights to and shapes what modelings can deliver.\n",
        "\n",
        "Over 80% of time are spent on data work (90%, as to my viewpoint), that is real but have to go through. But here I mainly want to practice on sklearn's pipeline (data pipeline and model pipeline), and also want to test out whether I can bring TensorFlow Neural Network into sklearn's pipelines.\n",
        "\n",
        "Mlflow from databricks is a side aim to be practice on. Somedays' ago I played with H2o (a java based auto ml module/library), calling the API both from R and python interface. The tracking webpage are the same for R and python. It is nice and \"auto\", but the speed is too slow, and the modles in it is limited. In nowdays, people in the field of ML/DL have to quickly adapt to front edge new algorithms. Recently I saw an article saying that algorithm (named \"rope\") from a paper in late last year has already been implemented in major GPT products. The key matrix used in \"rope\" seems a wavelet transformer. The most simply wavelet, corresponding to the \"harr\" functions, is with $\\theta=45Â°$, while \"rope\" uses a more customized $\\theta$. Signals in brain is transferrred by certain eletric pulse, a single neuron /cell can only perform  a simple task. So I think the transformer which use 2, or $e$, as exponentail base is bio-reasonable. More nerons can then form some groups, layers etc to process complex unstructured information. So generally, more nerons in the layers, more \"groups\" of nerons (like GPU), simple  (linear feeding) task to each nero but complex (non linear) task to groups of neoro (layers), those setttings often can produce better results. On a related note, I once authored a Bash script that proved highly effective. Beyond considering the tree-based structure of the Linux file system, what truly inspired me was nature and life science. Almost every living entity on Earth, from complex organisms to individual cells and even viruses, have a shell/film to separate its inner environment from outside. For complex lifes, cells have membrance, organs have films, and in the most outside, skin or bone/scale alike to make the \"firewall\" to stable each cell groups' functions and better tolerance changes in outside. Doesn't this concept closely resemble that of \"Docker\"?"
      ],
      "metadata": {
        "id": "f4EGwu4k2GB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Titanic dataset from OpenML\n",
        "titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
        "data = titanic.frame\n",
        "\n",
        "# Drop columns\n",
        "data.drop(['name', 'boat', 'body', 'home.dest'], axis=1, inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop('survived', axis=1)\n",
        "y = data['survived'].astype('int64')\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Lists of column names\n",
        "numeric_features = ['age', 'fare', 'sibsp', 'parch']\n",
        "categorical_features = ['sex', 'cabin', 'embarked', 'ticket', 'pclass']\n",
        "# Update the list of categorical features to exclude 'embarked' since we're handling it separately\n",
        "categorical_features.remove('embarked')"
      ],
      "metadata": {
        "id": "qlqfzTiX1jEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data is loaded, the next step is to define the data processing functions and classes. I appreciate the design of sklearn's pipeline, as it offers a clear and structured approach to consolidating findings from EDA. Prior to establishing the data pipeline, a significant amount of effort has already been invested in determining the optimal way to prepare the data for modeling."
      ],
      "metadata": {
        "id": "3CgLgJClA0bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric Transformer\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "# Categorical Transformer\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmbarkedTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Fill missing values and then fit the one-hot encoder\n",
        "        X_filled = np.where(pd.isnull(X), 'S', X)\n",
        "        self.onehot_encoder.fit(X_filled.reshape(-1, 1))\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Fill missing values\n",
        "        X_filled = np.where(pd.isnull(X), 'S', X)\n",
        "        # Transform using the one-hot encoder\n",
        "        X_onehot_encoded = self.onehot_encoder.transform(X_filled.reshape(-1, 1))\n",
        "        return X_onehot_encoded\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        return self.onehot_encoder.get_feature_names_out(input_features)\n",
        "\n",
        "\n",
        "# Numeric Transformer\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical Transformer for OneHotEncoding without prefix\n",
        "onehot_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
        "])\n",
        "\n",
        "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Convert to 1D array or Series\n",
        "        X_1d = X.iloc[:, 0] if isinstance(X, pd.DataFrame) else X.ravel()\n",
        "\n",
        "        # Add a placeholder for unknown categories\n",
        "        X_extended = np.concatenate([X_1d, ['__unknown__']])\n",
        "        self.encoder.fit(X_extended)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Convert to 1D array or Series\n",
        "        X_1d = X.iloc[:, 0] if isinstance(X, pd.DataFrame) else X.ravel()\n",
        "\n",
        "        # Replace unseen categories with the placeholder\n",
        "        X_transformed = pd.Series(X_1d).map(lambda x: x if x in self.encoder.classes_ else '__unknown__')\n",
        "\n",
        "        return self.encoder.transform(X_transformed).reshape(-1, 1)\n",
        "\n",
        "# Update the full preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('onehot', onehot_transformer, ['sex']),\n",
        "        ('cabin', CustomLabelEncoder(), ['cabin']),\n",
        "        ('ticket', CustomLabelEncoder(), ['ticket']),\n",
        "        ('embarked', EmbarkedTransformer(), ['embarked'])\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "lPfEqPRmQA0N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the data preprocessing is complete, I frequently desire to inspect the results to ensure the transformers operate as anticipated. The subsequent steps are primarily for validation and verification. This challenge is akin to what I've encountered with shiny in both R and Python. Although I managed to get the Python shiny working, it can sometimes crash with frustrating errors. This is a limitation I perceive in sklearn's data pipeline. Perhaps my familiarity with these tools is still growing; with more practice, I hope these methodologies will seamlessly integrate into my workflow."
      ],
      "metadata": {
        "id": "wY3htBoOCJci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Transform X_train using preprocessor\n",
        "_ = preprocessor.fit(X_train)\n",
        "X_train_transformed = preprocessor.transform(X_train)\n",
        "features_in=X_train_transformed.shape[1]\n",
        "features_in"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMvSrg43QA3P",
        "outputId": "74fadb5d-8f0d-48cb-e1c9-84554b6e0814"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Extract transformed feature names from each transformer\n",
        "# Numeric columns remain unchanged\n",
        "numeric_columns = numeric_features\n",
        "\n",
        "# One-hot encoded columns\n",
        "onehot_col = preprocessor.named_transformers_['onehot'].named_steps['onehot'].get_feature_names_out(['sex'])\n",
        "\n",
        "# For cabin and ticket, since they are label encoded, their column names remain the same\n",
        "label_encoded_col = ['cabin', 'ticket']\n",
        "\n",
        "# Embarked columns\n",
        "embark_col = preprocessor.named_transformers_['embarked'].get_feature_names_out(['embarked'])\n",
        "\n",
        "# 3. Construct the dataframe\n",
        "all_columns = numeric_columns + list(onehot_col) + label_encoded_col + list(embark_col)\n",
        "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns=all_columns)\n",
        "\n",
        "# Display the dataframe\n",
        "print(X_train_transformed_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1gaek2kQYAK",
        "outputId": "12109246-2753-4683-f364-9ee2cca39380"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        age      fare     sibsp     parch  sex_male  cabin  ticket  \\\n",
            "0 -0.981390 -0.495582 -0.495964 -0.442432       1.0  162.0   435.0   \n",
            "1  0.506426 -0.445269 -0.495964 -0.442432       1.0  162.0   628.0   \n",
            "2 -0.903084  0.890700 -0.495964  1.795376       0.0  148.0     1.0   \n",
            "3  1.367793  3.747624  0.456833 -0.442432       1.0   81.0   699.0   \n",
            "4  0.000000  0.171035 -0.495964 -0.442432       1.0  162.0    50.0   \n",
            "\n",
            "   embarked_C  embarked_Q  embarked_S  \n",
            "0         0.0         0.0         1.0  \n",
            "1         0.0         0.0         1.0  \n",
            "2         0.0         0.0         1.0  \n",
            "3         1.0         0.0         0.0  \n",
            "4         0.0         0.0         1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(X_train.embarked)\n",
        "z=EmbarkedTransformer()\n",
        "z.fit(X_train.embarked.to_frame())\n",
        "X_train_processed = z.transform(X_train.embarked.to_frame())\n",
        "X_train_processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiwMp4fFQayQ",
        "outputId": "7003fc3f-887a-4a7d-fcae-2bafc582b44d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the data successfully pipelined, the next step is to define the classifiers. These can either be those available in sklearn or custom-built to integrate with sklearn. Tensorflow is frequently utilized as a standalone module, but I'm hopeful that with the help from most recent scikeras it can be combined with other ML methods for production use. The real excitement begins now."
      ],
      "metadata": {
        "id": "b0lXqeceDwLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the individual classifiers\n",
        "# Define the Random Forest classifier with the given parameters\n",
        "rf_params = {\n",
        "    'n_estimators': 400,\n",
        "    'max_depth': 5,\n",
        "    'min_samples_leaf': 3,\n",
        "    'max_features' : 'sqrt',\n",
        "}\n",
        "rf = RandomForestClassifier(random_state=None,**rf_params)\n",
        "\n",
        "# Extra Trees Parameters\n",
        "et_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators':400,\n",
        "    'max_depth': 5,\n",
        "    'min_samples_leaf': 2,\n",
        "}\n",
        "et = ExtraTreesClassifier(random_state=None,**et_params)\n",
        "\n",
        "# AdaBoost parameters\n",
        "ada_params = {\n",
        "    'n_estimators': 400,\n",
        "    'learning_rate' : 0.65\n",
        "}\n",
        "ab = AdaBoostClassifier(random_state=None,**ada_params)\n",
        "\n",
        "# Gradient Boosting parameters\n",
        "gb_params = {\n",
        "    'n_estimators': 400,\n",
        "    'max_depth': 6,\n",
        "}\n",
        "gb = GradientBoostingClassifier(random_state=None,**gb_params)\n",
        "\n",
        "nb = GaussianNB()  # Naive Bayes\n",
        "\n",
        "svc = SVC(C=1.0, kernel='rbf', gamma='scale', probability=True, random_state=None)\n",
        "  # Support Vector Classifier Setting probability to True so we can use it for soft voting\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)  # Logistic Regression Setting max_iter to a higher value for convergence\n",
        "\n",
        "nn = MLPClassifier(hidden_layer_sizes=(512, 256, 128, 64, 32), max_iter=100000, alpha=0.0001,\n",
        "                     solver='adam', random_state=None)    # Define the neural network\n",
        "\n",
        "# Define the neural network model using TensorFlow's Keras API\n",
        "def create_nn_model():\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_shape=(features_in,)),  # input shape is the number of features\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='sigmoid'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')  # binary classification\n",
        "    ])\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "tfnn = KerasClassifier(\n",
        "    create_nn_model,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=['accuracy'],\n",
        "    epochs=300,\n",
        "    verbose=0\n",
        "    #hidden_layer_dim=100,\n",
        ")\n",
        "\n",
        "# List of classifiers for the voting classifier\n",
        "classifiers = [\n",
        "    ('rf', rf),\n",
        "    ('et', et),\n",
        "    ('ab', ab),\n",
        "    ('gb', gb),\n",
        "    ('nb', nb),\n",
        "    ('svc', svc),\n",
        "    ('lr', lr),\n",
        "    ('nn', nn),\n",
        "    ('tfnn', tfnn)\n",
        "]"
      ],
      "metadata": {
        "id": "1VV1oKdNQftY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I get all 9 classifiers, including tensorflow nn classifier, together in a list of model-shell. This is very like the functions, $y=f_i(x)$, have been defined analytically. Next step is just feed data ($x$) into these $f_i(x)$ to get output ($y$). Sending those classifiers ($f_i(x)$) as parameters to a loop to get output ($y$) from various $f_i(x)$. When X_train and y_train is feed in as input, the $f_i(x)$ is finally well defined, as those constant, parameters in $f_i(x)$ all get its most insightful value from input data. When X_test and y_test is feed to $f_i(x)$, we are using the insights we gained from training data to shed light on those data which are not seen in before by the current model. Here there is an assumption. that is, we suppose the unseen data and the training data are from similar settings. Hence the insight we learn from those training data can be applied to those new unseen data. When this assumption is no longer hold, or somewhat changed after some time period , then we have to collect data to recalibrate or even a complete model rebuild."
      ],
      "metadata": {
        "id": "4RzZq4MPEyqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to evaluate a model\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name, prt=True):\n",
        "    # Create a pipeline with the preprocessor and the classifier\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', model)])\n",
        "\n",
        "    # Fit the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    preds = pipeline.predict(X_test)  #for hard voting\n",
        "    proba_preds = pipeline.predict_proba(X_test)  #for soft voting\n",
        "\n",
        "    # Calculate accuracy and F1 score\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "\n",
        "    if prt==True:\n",
        "        print(f\"{model_name} Accuracy:\", accuracy)\n",
        "        print(f\"{model_name} F1 Score:\", f1)\n",
        "        print(\"------\")\n",
        "    return accuracy, f1, preds,proba_preds"
      ],
      "metadata": {
        "id": "yFPV6cCNQjm0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the bulk of the preparatory work completed, we're ready to move on to the next phase: loading data into our models and evaluating their performance. While accuracy is a commonly used metric for classifiers, precision and recall often offer deeper insights, especially in imbalanced datasets or specific application contexts. For this reason, I'll compute both accuracy and the F1 score, which harmonizes precision and recall, for each classifier. Additionally, I'll save the predictions made on the test data for potential ensemble modeling in the subsequent steps."
      ],
      "metadata": {
        "id": "_kjVFcxFIQCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "predictions = {}\n",
        "proba_predictions = {}\n",
        "for name, model in classifiers:\n",
        "    accuracy, f1, preds, proba_preds= evaluate_model(model, X_train, y_train, X_test, y_test, name)\n",
        "    predictions[name] = preds\n",
        "    proba_predictions[name] = proba_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mnXwPCXQjyc",
        "outputId": "16d8671a-9386-4d11-f16f-708791933b3d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rf Accuracy: 0.7900763358778626\n",
            "rf F1 Score: 0.7317073170731707\n",
            "------\n",
            "et Accuracy: 0.767175572519084\n",
            "et F1 Score: 0.7109004739336493\n",
            "------\n",
            "ab Accuracy: 0.5229007633587787\n",
            "ab F1 Score: 0.617737003058104\n",
            "------\n",
            "gb Accuracy: 0.7824427480916031\n",
            "gb F1 Score: 0.7135678391959799\n",
            "------\n",
            "nb Accuracy: 0.7213740458015268\n",
            "nb F1 Score: 0.6217616580310881\n",
            "------\n",
            "svc Accuracy: 0.5763358778625954\n",
            "svc F1 Score: 0.17777777777777776\n",
            "------\n",
            "lr Accuracy: 0.767175572519084\n",
            "lr F1 Score: 0.7081339712918661\n",
            "------\n",
            "nn Accuracy: 0.6450381679389313\n",
            "nn F1 Score: 0.39215686274509803\n",
            "------\n",
            "tfnn Accuracy: 0.7595419847328244\n",
            "tfnn F1 Score: 0.7069767441860464\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model ensembling offers various techniques such as voting, bagging, and stacking. While ensemble methods often deliver superior results, there's no absolute assurance of this outcome. Individual models can benefit from hyperparameter tuning. Commonly, grid search is employed for this purpose, but it can be time-intensive and cumbersome. Generally, performance improvements follow a growth curveârapid gains initially, with diminishing returns as the model matures.\n",
        "\n",
        "During my studies on simulation, bagging, boosting, and particularly methods like MCMC, I was deeply fascinated. However, my professor cautioned me that these aren't silver bullets for every problem. For instance, in bootstrapping, order statistics don't always respond well, especially for extreme values. Thus, when dealing with rare events or outliers, bootstrapping might not be the most effective strategy."
      ],
      "metadata": {
        "id": "dd38x820Jds6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard voting\n",
        "stacked_preds = np.column_stack([predictions[name[0]] for name in classifiers])\n",
        "from scipy.stats import mode\n",
        "voting_preds = mode(stacked_preds, axis=1).mode.ravel()\n",
        "voting_accuracy = accuracy_score(y_test, voting_preds)\n",
        "print(\"Voting Accuracy:\", voting_accuracy)\n",
        "voting_f1 = f1_score(y_test, voting_preds)\n",
        "print(\"Voting F1 Score:\", voting_f1)\n",
        "\n",
        "# Soft voting\n",
        "stacked_proba_preds = np.dstack([proba_predictions[name[0]] for name in classifiers])\n",
        "avg_proba = np.mean(stacked_proba_preds, axis=2)\n",
        "voting_proba_preds = np.argmax(avg_proba, axis=1)\n",
        "voting_accuracy = accuracy_score(y_test, voting_proba_preds)\n",
        "print(\"Voting (Soft) Accuracy:\", voting_accuracy)\n",
        "voting_f1 = f1_score(y_test, voting_proba_preds)\n",
        "print(\"Voting (Soft) F1 Score:\", voting_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojCqb_eNQj2G",
        "outputId": "6b43c5a1-bb4a-49a0-8ed5-b67c92a503aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Accuracy: 0.7709923664122137\n",
            "Voting F1 Score: 0.7087378640776699\n",
            "Voting (Soft) Accuracy: 0.7633587786259542\n",
            "Voting (Soft) F1 Score: 0.6804123711340205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classifiers.remove(('tfnn',tfnn))  # next to practice with bagging, tfnn as a compatianle classifer theratically can be included, however, tfnn takes long time to train hence not included in bagging."
      ],
      "metadata": {
        "id": "qKVNIfIRRV7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from scipy.stats import mode\n",
        "\n",
        "def evaluate_bagged_model(base_model, X_train, y_train, X_test, y_test, model_name):\n",
        "    # Create a pipeline with the preprocessor and the bagging classifier\n",
        "    bagging_clf = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=None)\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('classifier', bagging_clf)])\n",
        "\n",
        "    # Fit the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    preds = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy and F1 score\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "\n",
        "    print(f\"Bagged {model_name} Accuracy:\", accuracy)\n",
        "    print(f\"Bagged {model_name} F1 Score:\", f1)\n",
        "    print(\"------\")\n",
        "\n",
        "    return preds\n",
        "\n",
        "# Collect predictions from each bagged model\n",
        "all_preds = []\n",
        "\n",
        "for name, model in classifiers:\n",
        "    preds = evaluate_bagged_model(model, X_train, y_train, X_test, y_test, name)\n",
        "    all_preds.append(preds)\n",
        "\n",
        "# Transpose the list of predictions\n",
        "all_preds_transposed = np.array(all_preds).T\n",
        "\n",
        "# Hard voting: Use mode to get the most common prediction for each instance\n",
        "voting_preds = mode(all_preds_transposed, axis=1).mode.ravel()\n",
        "\n",
        "# Calculate accuracy and F1 score for the voting ensemble\n",
        "voting_accuracy = accuracy_score(y_test, voting_preds)\n",
        "voting_f1 = f1_score(y_test, voting_preds)\n",
        "\n",
        "print(\"Voting Ensemble Accuracy:\", voting_accuracy)\n",
        "print(\"Voting Ensemble F1 Score:\", voting_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC1o0hg7Qj5Q",
        "outputId": "ce5d662d-fabb-41cf-c33d-a1a96ccadddf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagged rf Accuracy: 0.7595419847328244\n",
            "Bagged rf F1 Score: 0.6865671641791045\n",
            "------\n",
            "Bagged et Accuracy: 0.7709923664122137\n",
            "Bagged et F1 Score: 0.7169811320754716\n",
            "------\n",
            "Bagged ab Accuracy: 0.6564885496183206\n",
            "Bagged ab F1 Score: 0.6785714285714286\n",
            "------\n",
            "Bagged gb Accuracy: 0.7786259541984732\n",
            "Bagged gb F1 Score: 0.707070707070707\n",
            "------\n",
            "Bagged nb Accuracy: 0.7213740458015268\n",
            "Bagged nb F1 Score: 0.6217616580310881\n",
            "------\n",
            "Bagged svc Accuracy: 0.5801526717557252\n",
            "Bagged svc F1 Score: 0.19117647058823528\n",
            "------\n",
            "Bagged lr Accuracy: 0.7633587786259542\n",
            "Bagged lr F1 Score: 0.7047619047619047\n",
            "------\n",
            "Bagged nn Accuracy: 0.6450381679389313\n",
            "Bagged nn F1 Score: 0.41509433962264153\n",
            "------\n",
            "Bagged tfnn Accuracy: 0.7595419847328244\n",
            "Bagged tfnn F1 Score: 0.7014218009478673\n",
            "------\n",
            "Voting Ensemble Accuracy: 0.7557251908396947\n",
            "Voting Ensemble F1 Score: 0.6831683168316832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is for testing tensorflow nn classifier to be used as sklearn classifier\n",
        "#just like what I have done with the data pipeline, when integrated together, it has to have a way to test out separately.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier  #this has been migrated to the following\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor  #pip install scikeras[tensorflow]\n",
        "\n",
        "# Process the data using the preprocessor pipeline\n",
        "X_train_processed = preprocessor.transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "#y_train = y_train.astype(np.int64)\n",
        "#y_test = y_test.astype(np.int64)\n",
        "\n",
        "# Define the neural network model using TensorFlow's Keras API\n",
        "def create_nn_model():\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_shape=(X_train_processed.shape[1],)),  # input shape is the number of features\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='sigmoid'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')  # binary classification\n",
        "    ])\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "clf = KerasClassifier(\n",
        "    create_nn_model,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=['accuracy'],\n",
        "    epochs=100,\n",
        "    verbose=0\n",
        "    #hidden_layer_dim=100,\n",
        ")\n",
        "\n",
        "\n",
        "# Wrap the model using KerasClassifier\n",
        "tf_nn = clf\n",
        "#tf_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "tf_nn.fit(X_train_processed, y_train),\n",
        "\n",
        "# 4. Evaluate the model\n",
        "#loss, accuracy = tf_nn.fit(X_test_processed, y_test, verbose=0)\n",
        "\n",
        "nn_preds = (tf_nn.predict(X_test_processed, verbose=0) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, nn_preds)\n",
        "print(f\"NN Accuracy: {accuracy}\")\n",
        "nn_f1 = f1_score(y_test, nn_preds)\n",
        "print(f\"NN F1 Score: {nn_f1}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6RC-ShOQj8P",
        "outputId": "d8e32016-cb9f-4d6b-f33f-dbe842c7fa67"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Accuracy: 0.6221374045801527\n",
            "NN F1 Score: 0.3443708609271523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Appendix 2: Initial Version for Practice Code Development, Data Steps, Single Classifier Testing, and MLflow Experimentation.\n",
        "\n",
        "The data processing steps in these codes are in a \"test and try\" mode. The goal is to refine these steps to align more closely with the pipeline conventions and best practices of scikit-learnâensuring the process is more structured and clean (as in the above). (Note: The data treatment in this version might differ as it's primarily for testing purposes.)\n",
        "\n",
        "When employing cross-validation, it's acceptable to perform model comparisons, voting, etc., based on the training data rather than the testing data. However, to achieve a more comprehensive model performance evaluation, it might be beneficial to also consider the X_test, y_test, and predictions on the test set. Additionally, incorporating metrics related to precision and recall can provide deeper insights into model performance."
      ],
      "metadata": {
        "id": "Us_cp6WIP2bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score,cross_val_predict\n",
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Fetch Titanic dataset from OpenML\n",
        "titanic = fetch_openml(\"titanic\", version=1, as_frame=True)\n",
        "data = titanic.frame\n",
        "\n",
        "# Preprocess the data\n",
        "data = data.drop(['name','boat', 'body', 'home.dest'], axis=1)\n",
        "df=data.copy()\n",
        "df.isnull().sum(0)\n",
        "df.iloc[:,8].isnull().sum()\n",
        "df.head()\n",
        "df.info()\n",
        "\n",
        "data['sex'] = LabelEncoder().fit_transform(data['sex'].astype(str))\n",
        "data['embarked'] = data['embarked'].fillna('S')\n",
        "data['embarked'] = LabelEncoder().fit_transform(data['embarked'].astype(str))\n",
        "data['age'] = data['age'].fillna(data['age'].mean())\n",
        "data['fare'] = data['fare'].fillna(data['fare'].mean())\n",
        "\n",
        "# For the 'ticket' and 'cabin' columns, fill missing values with a placeholder ('Unknown' in this case)\n",
        "for col in ['ticket','cabin']:\n",
        "    data[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Encode 'ticket' and 'cabin' columns\n",
        "label_encoders = {}  # to store label encoders for each column (useful for inverse transform later if needed)\n",
        "for col in ['ticket','cabin']:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "#data=data.drop(['age','fare','embarked','cabin'],axis=1)\n",
        "# Define features and target\n",
        "X = data.drop('survived', axis=1)\n",
        "y = data['survived'].astype(int)  #.astype('int64')\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZmS3y64Qj-g",
        "outputId": "0a5fdd87-fd8d-4cb6-9583-993b2796c394"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1309 entries, 0 to 1308\n",
            "Data columns (total 10 columns):\n",
            " #   Column    Non-Null Count  Dtype   \n",
            "---  ------    --------------  -----   \n",
            " 0   pclass    1309 non-null   float64 \n",
            " 1   survived  1309 non-null   category\n",
            " 2   sex       1309 non-null   category\n",
            " 3   age       1046 non-null   float64 \n",
            " 4   sibsp     1309 non-null   float64 \n",
            " 5   parch     1309 non-null   float64 \n",
            " 6   ticket    1309 non-null   object  \n",
            " 7   fare      1308 non-null   float64 \n",
            " 8   cabin     295 non-null    object  \n",
            " 9   embarked  1307 non-null   category\n",
            "dtypes: category(3), float64(5), object(2)\n",
            "memory usage: 75.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()\n",
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBmzjWL4vhTh",
        "outputId": "c2b02ba6-113d-4522-ab46-3255c6657526"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1309 entries, 0 to 1308\n",
            "Data columns (total 9 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   pclass    1309 non-null   float64\n",
            " 1   sex       1309 non-null   int64  \n",
            " 2   age       1309 non-null   float64\n",
            " 3   sibsp     1309 non-null   float64\n",
            " 4   parch     1309 non-null   float64\n",
            " 5   ticket    1309 non-null   int64  \n",
            " 6   fare      1309 non-null   float64\n",
            " 7   cabin     1309 non-null   int64  \n",
            " 8   embarked  1309 non-null   int64  \n",
            "dtypes: float64(5), int64(4)\n",
            "memory usage: 92.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define the Random Forest classifier with the given parameters\n",
        "rf_params = {\n",
        "    'n_estimators': 400,\n",
        "    'max_depth': 5,\n",
        "    'min_samples_leaf': 3,\n",
        "    'max_features' : 'sqrt',\n",
        "}\n",
        "clf = RandomForestClassifier(**rf_params)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(clf, X, y, cv=5)\n",
        "\n",
        "# Print the CV scores\n",
        "print(\"5-fold CV scores:\", cv_scores)\n",
        "print(\"Average CV score with refined parameters:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urz10RcOx00u",
        "outputId": "bd0e8416-6ca1-4fb9-859e-417d8c3dbe0c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-fold CV scores: [0.51526718 0.83969466 0.64885496 0.71374046 0.64750958]\n",
            "Average CV score with refined parameters: 0.6730133660904917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "mlflow.set_experiment('Titanic - classification_model')\n",
        "with mlflow.start_run():\n",
        "    # Log average CV score as a metric\n",
        "    mlflow.log_metric(\"average_cv_score\", cv_scores.mean())\n",
        "\n",
        "    # Train the model on full data (to log the model artifact)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(clf, \"model\")\n",
        "\n",
        "    # Set tags for clarity\n",
        "    mlflow.set_tag(\"framework\", \"scikit-learn\")\n",
        "    mlflow.set_tag(\"dataset\", \"Titanic\")\n",
        "\n",
        "    print(\"Model and metrics saved in run %s\" % mlflow.active_run().info.run_uuid)\n",
        "    # Calculate and log accuracy to MLFlow\n",
        "\n",
        "    # Predictions\n",
        "    predictions = clf.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    mlflow.log_metric('accuracy', accuracy)\n",
        "    print('Accuracy: %f' % accuracy)\n",
        "\n",
        "    # Calculate and log F1 score to MLFlow\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    mlflow.log_metric('f1', f1)\n",
        "    print('F1 Score: %f' % f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km4tFExPybku",
        "outputId": "8e605d50-efc8-4405-e944-4278e6358752"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and metrics saved in run 4cb4d6c17c484ed3981313b9e7d7a9b4\n",
            "Accuracy: 0.790076\n",
            "F1 Score: 0.702703\n"
          ]
        }
      ]
    }
  ]
}