{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1huf3m6_1UyXtJOrJDUfZ6lEEIWGDu6y5",
      "authorship_tag": "ABX9TyPGRWQW51eGnLXWouL6unlL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ellen-Gu/Quantitative-Analysis/blob/main/Exploring_and_Advancing_in_AI_(part_2)_A_Journey_with_tensorflow%2C_pytorch%2C_LLMs%2C_Quantized_Models_and_APP_development%2C_and_Continuous_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 12/06/2023 update: Successfully resolved the Langchain issue. GPU acceleration is now fully operational in Langchain\n",
        "\n",
        "After extensive research and adjustments, I've successfully enabled GPU acceleration in Langchain on my new laptop equipped with an NVIDIA GeForce 4090 GPU. Initially, both my older laptop with a Quadro M1200 GPU and the new one faced issues. While the GPUs were recognized by llam.cpp, TensorFlow, PyTorch, and Docker, Langchain encountered errors during prompt responses, indicating a lack of compatible GPU acceleration.\n",
        "\n",
        "The breakthrough came from a suggestion about version alignment. It turned out that the CUDA version in my Docker environment (12.3) didn't match the host system's version (12.2). Resolving this inconsistency was key. I chose to upgrade the CUDA version on the host system, ensuring compatibility with the Docker environment. This alignment led to successful GPU acceleration in Langchain and other packages after a system reboot.\n",
        "\n",
        "However, the same adjustments on my older laptop didn't yield the same results. Langchain, which initially released in October 2022 and stabilized in November 2023, may not support older GPU models. Additionally, my older laptop is confined to Windows 10, unable to upgrade to Windows 11, and there are known issues with WSL on Windows 10 regarding GPU version recognition. A clean installation might offer further insights, but for now, my focus has shifted to other projects, leaving the older system as is.\n",
        "\n",
        "#### End of 12/06/2023 update\n"
      ],
      "metadata": {
        "id": "vOpYc7VEaiNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# original contents start from here"
      ],
      "metadata": {
        "id": "wfEl_-Kxk5xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gguf (converted and quantized) download from huggieface may ran into errors when trying to accelerating with GPU. This may related to some cpmpatible issues with windows system/WSL.  However, I think if llama.cpp can re-compile, make and quantize locally then we may bypass the issue and gain more advantage to quantize other llama type models.\n",
        "\n",
        "I encounter this issue with llam.cpp, even though nvidia card is working perfectly with tensorflow and pytorch locally on my laptop. Today I read a shortcut on Oreilly. It leads through how to use llama.cpp to re-compile, make and quantizeand with GPU acceleration. I decide to give it a try. After some twick it works! Now I can shift 32 layers out of 35 layers of 7b model to GPU. I wonder that the quantized model download from huggieface may contain some more trainings. But the style of locally re-compiled and quantized model seems more fit in my expectations.\n",
        "\n",
        "The git rep are at https://github.com/facebookresearch/llama and https://github.com/ggerganov/llama.cpp.git. After downloading the git rep one can run as instarcted the ./downloas.sh . If in the middle of downloading there are some internet interupts, just rerun this sh, it will automatically continue from the place where the internt is interupted.\n",
        "\n",
        "After get all llama model files and the git rep, the first step is check whether the nvidia card works, and whether cuda toolkit is installed properly. For my current laptop (more than five years old), the GPU card and nvcc version details are as below:\n"
      ],
      "metadata": {
        "id": "8dK9fQ7A-Sax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzZ1Jytf-PX-",
        "outputId": "401311f1-2d1a-44bf-ea38-056f3ec9e52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
            "Built on Fri_Sep__8_19:17:24_PDT_2023\r\n",
            "Cuda compilation tools, release 12.3, V12.3.52\r\n",
            "Build cuda_12.3.r12.3/compiler.33281558_0\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nttGSVXC-Q1R",
        "outputId": "ded54ef5-f4bf-42da-d0c1-180c16fbc2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 28 03:49:47 2023       \r\n",
            "+---------------------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 535.129.01             Driver Version: 537.70       CUDA Version: 12.2     |\r\n",
            "|-----------------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                                         |                      |               MIG M. |\r\n",
            "|=========================================+======================+======================|\n",
            "|   0  Quadro M1200                   On  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A    0C    P8              N/A / 200W |      0MiB /  4096MiB |      1%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A        22      G   /Xwayland                                 N/A      |\n",
            "|    0   N/A  N/A        22      G   /Xwayland                                 N/A      |\n",
            "|    0   N/A  N/A        23      G   /Xwayland                                 N/A      |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After verifing the nvcc version and nvidia-smi, which is expected to work normally, we can add the cuda home path, make a 7B subfolder inside the ./llama folder, and most of all, change the vocab count in the params.json file in the folder downloaded from facebook. This will make the re-compile/make/quantize error free. Other parts from Oreilly shortcut are working fine. I do not fully follow the instruction on the git rep from facebook, instead I generally follow the steps on Oreilly shortcut, and it works well after twick and correct as below."
      ],
      "metadata": {
        "id": "Yz6pqhdsDLpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export CUDA_HOME=/usr/local/cuda-12.3\n",
        "mkdir models/7B\n",
        "nano ../llama/llama-2-7b-chat/params.json   # change vocab from -1 to 32000\n",
        "# the only errors I encounter with oreilly shortcut codes for recompile and cquantize with llama.cpp are above,\n",
        "# the vocab para in llama.cpp folder needs to be changed to 32000, which I think are the vocab count in 7b model.\n",
        "# usually 5k vocab is ok for normal chat, 30k is good enough, 50k is more than enough, 100k is language experts which is rare in daily activities.\n"
      ],
      "metadata": {
        "id": "iEEahiFM-Q4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After all settled, the quantized 7b works directly in terminal. The model details are as below."
      ],
      "metadata": {
        "id": "6bDa5fXXEJ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /home/sharedspace/gguf-cpp/llama.cpp && \\\n",
        " ./main -m ./models/7B/ggml-model-q4_0.gguf -n 1024 --repeat_penalty 1.0 --color -i -r \"User:\" -f ./prompts/chat-with-bob.txt --n-gpu-layers 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NIZw6F3-RA6",
        "outputId": "2be79f75-5ff2-4ab2-9e1f-229c0de9c288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log start\r\n",
            "main: build = 1571 (bb03290)\r\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\r\n",
            "main: seed  = 1701144246\n",
            "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "  Device 0: Quadro M1200, compute capability 5.0\n",
            "llama_model_loader: loaded meta data with 16 key-value pairs and 291 tensors from ./models/7B/ggml-model-q4_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: - tensor    0:                token_embd.weight q4_0     [  4096, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor    1:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor    2:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor    3:              blk.0.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    4:              blk.0.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    5:              blk.0.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    6:         blk.0.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    7:            blk.0.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor    8:            blk.0.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    9:              blk.0.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   10:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   11:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   12:              blk.1.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   13:              blk.1.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   14:              blk.1.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   15:         blk.1.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   16:            blk.1.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   17:            blk.1.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   18:              blk.1.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   19:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   20:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   21:              blk.2.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   22:              blk.2.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   23:              blk.2.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   24:         blk.2.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   25:            blk.2.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   26:            blk.2.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   27:              blk.2.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   28:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   29:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   30:              blk.3.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   31:              blk.3.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   32:              blk.3.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   33:         blk.3.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   34:            blk.3.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   35:            blk.3.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   36:              blk.3.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   37:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   38:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   39:              blk.4.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   40:              blk.4.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   41:              blk.4.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   42:         blk.4.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   43:            blk.4.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   44:            blk.4.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   45:              blk.4.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   46:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   47:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   48:              blk.5.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   49:              blk.5.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   50:              blk.5.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   51:         blk.5.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   52:            blk.5.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   53:            blk.5.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   54:              blk.5.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   55:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   56:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   57:              blk.6.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   58:              blk.6.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   59:              blk.6.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   60:         blk.6.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   61:            blk.6.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   62:            blk.6.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   63:              blk.6.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   64:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   65:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   66:              blk.7.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   67:              blk.7.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   68:              blk.7.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   69:         blk.7.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   70:            blk.7.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   71:            blk.7.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   72:              blk.7.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   73:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   74:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   75:              blk.8.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   76:              blk.8.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   77:              blk.8.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   78:         blk.8.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   79:            blk.8.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   80:            blk.8.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   81:              blk.8.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   82:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   83:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   84:              blk.9.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   85:              blk.9.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   86:              blk.9.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   87:         blk.9.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   88:            blk.9.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   89:            blk.9.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   90:              blk.9.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   91:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   92:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   93:             blk.10.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   94:             blk.10.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   95:             blk.10.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   96:        blk.10.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   97:           blk.10.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   98:           blk.10.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   99:             blk.10.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  100:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  101:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  102:             blk.11.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  103:             blk.11.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  104:             blk.11.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  105:        blk.11.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  106:           blk.11.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  107:           blk.11.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  108:             blk.11.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  109:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  110:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  111:             blk.12.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  112:             blk.12.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  113:             blk.12.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  114:        blk.12.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  115:           blk.12.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  116:           blk.12.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  117:             blk.12.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  118:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  119:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  120:             blk.13.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  121:             blk.13.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  122:             blk.13.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  123:        blk.13.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  124:           blk.13.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  125:           blk.13.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  126:             blk.13.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  127:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  128:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  129:             blk.14.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  130:             blk.14.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  131:             blk.14.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  132:        blk.14.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  133:           blk.14.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  134:           blk.14.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  135:             blk.14.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  136:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  137:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  138:             blk.15.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  139:             blk.15.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  140:             blk.15.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  141:        blk.15.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  142:           blk.15.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  143:           blk.15.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  144:             blk.15.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  145:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  146:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  147:             blk.16.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  148:             blk.16.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  149:             blk.16.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  150:        blk.16.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  151:           blk.16.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  152:           blk.16.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  153:             blk.16.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  154:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  155:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  156:             blk.17.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  157:             blk.17.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  158:             blk.17.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  159:        blk.17.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  160:           blk.17.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  161:           blk.17.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  162:             blk.17.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  163:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  164:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  165:             blk.18.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  166:             blk.18.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  167:             blk.18.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  168:        blk.18.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  169:           blk.18.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  170:           blk.18.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  171:             blk.18.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  172:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  173:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  174:             blk.19.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  175:             blk.19.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  176:             blk.19.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  177:        blk.19.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  178:           blk.19.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  179:           blk.19.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  180:             blk.19.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  181:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  182:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  183:             blk.20.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  184:             blk.20.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  185:             blk.20.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  186:        blk.20.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  187:           blk.20.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  188:           blk.20.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  189:             blk.20.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  190:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  191:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  192:             blk.21.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  193:             blk.21.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  194:             blk.21.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  195:        blk.21.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  196:           blk.21.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  197:           blk.21.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  198:             blk.21.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  199:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  200:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  201:             blk.22.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  202:             blk.22.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  203:             blk.22.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  204:        blk.22.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  205:           blk.22.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  206:           blk.22.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  207:             blk.22.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  208:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  209:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  210:             blk.23.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  211:             blk.23.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  212:             blk.23.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  213:        blk.23.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  214:           blk.23.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  215:           blk.23.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  216:             blk.23.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  217:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  218:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  219:             blk.24.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  220:             blk.24.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  221:             blk.24.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  222:        blk.24.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  223:           blk.24.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  224:           blk.24.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  225:             blk.24.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  226:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  227:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  228:             blk.25.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  229:             blk.25.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  230:             blk.25.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  231:        blk.25.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  232:           blk.25.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  233:           blk.25.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  234:             blk.25.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  235:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  236:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  237:             blk.26.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  238:             blk.26.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  239:             blk.26.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  240:        blk.26.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  241:           blk.26.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  242:           blk.26.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  243:             blk.26.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  244:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  245:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  246:             blk.27.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  247:             blk.27.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  248:             blk.27.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  249:        blk.27.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  250:           blk.27.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  251:           blk.27.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  252:             blk.27.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  253:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  254:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  255:             blk.28.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  256:             blk.28.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  257:             blk.28.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  258:        blk.28.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  259:           blk.28.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  260:           blk.28.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  261:             blk.28.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  262:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  263:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  264:             blk.29.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  265:             blk.29.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  266:             blk.29.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  267:        blk.29.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  268:           blk.29.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  269:           blk.29.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  270:             blk.29.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  271:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  272:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  273:             blk.30.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  274:             blk.30.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  275:             blk.30.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  276:        blk.30.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  277:           blk.30.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  278:           blk.30.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  279:             blk.30.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  280:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  281:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  282:             blk.31.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  283:             blk.31.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  284:             blk.31.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  285:        blk.31.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  286:           blk.31.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  287:           blk.31.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  288:             blk.31.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  289:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  290:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = llama\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 2048\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = mostly Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW) \n",
            "llm_load_print_meta: general.name   = llama\n",
            "llm_load_print_meta: BOS token = 1 '<s>'\n",
            "llm_load_print_meta: EOS token = 2 '</s>'\n",
            "llm_load_print_meta: UNK token = 0 '<unk>'\n",
            "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
            "llm_load_tensors: using CUDA for GPU acceleration\n",
            "llm_load_tensors: mem required  =  172.97 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 32/35 layers to GPU\n",
            "llm_load_tensors: VRAM used: 3475.00 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_new_context_with_model: kv self size  =  256.00 MiB\n",
            "llama_build_graph: non-view tensors processed: 740/740\n",
            "llama_new_context_with_model: compute buffer total size = 73.56 MiB\n",
            "llama_new_context_with_model: VRAM scratch buffer: 70.50 MiB\n",
            "llama_new_context_with_model: total VRAM used: 3545.50 MiB (model: 3475.00 MiB, context: 70.50 MiB)\n",
            "\n",
            "system_info: n_threads = 3 / 6 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
            "main: interactive mode on.\n",
            "Reverse prompt: 'User:'\n",
            "sampling: \n",
            "\trepeat_last_n = 64, repeat_penalty = 1.000, frequency_penalty = 0.000, presence_penalty = 0.000\n",
            "\ttop_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.800\n",
            "\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n",
            "generate: n_ctx = 512, n_batch = 512, n_predict = 1024, n_keep = 0\n",
            "\n",
            "\n",
            "== Running in interactive mode. ==\n",
            " - Press Ctrl+C to interject at any time.\n",
            " - Press Return to return control to LLaMa.\n",
            " - To return control without starting a new line, end your input with '/'.\n",
            " - If you want to submit another line, end your input with '\\'.\n",
            "\n",
            "\u001b[33m Transcript of a dialog, where the User interacts with an Assistant named Bob. Bob is helpful, kind, honest, good at writing, and never fails to answer the User's requests immediately and with precision.\n",
            "\n",
            "User: Hello, Bob.\n",
            "Bob: Hello. How may I help you today?\n",
            "User: Please tell me the largest city in Europe.\n",
            "Bob: Sure. The largest city in Europe is Moscow, the capital of Russia.\n",
            "User:\u001b[0m\u001b[1m\u001b[32m\u001b[0m\n",
            "\n",
            "llama_print_timings:        load time =    3559.91 ms\n",
            "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings: prompt eval time =    3242.75 ms /    99 tokens (   32.76 ms per token,    30.53 tokens per second)\n",
            "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_print_timings:       total time =   32528.84 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the outputs above we can see that 32 out of 35 layers of 7b model are now shifted to GPU for computing. I tryied 35 (default is 1000) but my GPU has only 4GB RAM hence only can hold 32 layers. I am very happy to see that finally the local quantized 7b model works with GPU support.\n",
        "\n",
        "I asked the same questions as in last time. Apparently, \"Bob\", the chat agent from the locally re-compile and quantized llama 7b model seems giving more preferrable responses. The followings are screenshot of chat between Bob and me, The yellow part is from the llama cpp git rep samples. Aside the \"Bob\" , there are some other sample prompt initialize files:"
      ],
      "metadata": {
        "id": "m57WKCmsJ0Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /home/sharedspace/gguf-cpp/llama.cpp/prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxxaLcLPUXPh",
        "outputId": "87cd0934-df19-4c10-84d6-b8f477e4ed56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 56\r\n",
            "-rwxrwsr-- 1 root sharedspace  106 Nov 27 15:06 alpaca.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace 2348 Nov 27 15:06 assistant.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace 1837 Nov 27 15:06 chat.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace   90 Nov 27 15:06 chat-with-baichuan.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace  386 Nov 27 15:06 chat-with-bob.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace  446 Nov 27 15:06 chat-with-vicuna-v0.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace  426 Nov 27 15:06 chat-with-vicuna-v1.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace 1538 Nov 27 15:06 dan-modified.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace 1663 Nov 27 15:06 dan.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace 2598 Nov 27 15:06 LLM-questions.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace 5086 Nov 27 15:06 mnemonics.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace 1716 Nov 27 15:06 parallel-questions.txt\r\n",
            "-rwxrwsr-- 1 root sharedspace  758 Nov 27 15:06 reason-act.txt\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(filename=\"/content/drive/MyDrive/Colab Notebooks/quantize-7bmodel-4bit.png\",width=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "ErjROFiQ-RET",
        "outputId": "8870799d-671a-44b8-dec5-14514fd7d67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 1000
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The recompiled and quantized 7b model works well on terminal. However, I still have some issue when trying to use GPU accelerating with LangChain. It looks like the window/wsl issue is at least also influenced LangChain. Maybe this will be ok with upgraded to win 11 as per some users opinons. Another issue with LangChain and locally quantized model is that for CPU usage, it seems not be able to answer as accuratly as models downladed from huggieface. I think the locally re-compiled and quantized model in the terminal gives the best answers. The followings are LangChain prompt/answer of the same set of question. It looks that this time instead of ignore the word King/Queen, it gets confused and give a non-relevent answer, as its last training is in Feb 2022."
      ],
      "metadata": {
        "id": "fYRlIeIjPW5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "n_gpu_layers = 0  # Change this value based on your model and your GPU VRAM pool: Set to 0 to use GPU syntax but run on CPU\n",
        "n_batch = 32  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "\n",
        "# Callbacks support token-wise streaming\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "# Make sure the model path is correct!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/home/sharedspace/gguf-cpp/llama.cpp/models/7B/ggml-model-q4_0.gguf\",\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    temperature=0,  # want answers not so randomly\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=True,  # Verbose is required to pass to the callback manager\n",
        "    max_tokens=1000 # adjusted from 256 (Default) to get more complete answers\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mKs-B7GMOXp",
        "outputId": "f40c7c51-0ebd-4f16-f5fd-fe2f296e640e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 16 key-value pairs and 291 tensors from /home/sharedspace/gguf-cpp/llama.cpp/models/7B/ggml-model-q4_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: - tensor    0:                token_embd.weight q4_0     [  4096, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor    1:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor    2:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor    3:              blk.0.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    4:              blk.0.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    5:              blk.0.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    6:         blk.0.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    7:            blk.0.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor    8:            blk.0.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    9:              blk.0.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   10:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   11:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   12:              blk.1.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   13:              blk.1.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   14:              blk.1.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   15:         blk.1.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   16:            blk.1.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   17:            blk.1.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   18:              blk.1.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   19:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   20:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   21:              blk.2.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   22:              blk.2.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   23:              blk.2.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   24:         blk.2.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   25:            blk.2.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   26:            blk.2.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   27:              blk.2.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   28:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   29:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   30:              blk.3.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   31:              blk.3.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   32:              blk.3.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   33:         blk.3.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   34:            blk.3.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   35:            blk.3.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   36:              blk.3.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   37:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   38:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   39:              blk.4.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   40:              blk.4.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   41:              blk.4.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   42:         blk.4.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   43:            blk.4.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   44:            blk.4.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   45:              blk.4.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   46:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   47:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   48:              blk.5.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   49:              blk.5.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   50:              blk.5.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   51:         blk.5.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   52:            blk.5.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   53:            blk.5.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   54:              blk.5.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   55:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   56:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   57:              blk.6.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   58:              blk.6.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   59:              blk.6.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   60:         blk.6.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   61:            blk.6.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   62:            blk.6.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   63:              blk.6.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   64:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   65:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   66:              blk.7.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   67:              blk.7.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   68:              blk.7.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   69:         blk.7.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   70:            blk.7.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   71:            blk.7.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   72:              blk.7.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   73:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   74:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   75:              blk.8.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   76:              blk.8.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   77:              blk.8.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   78:         blk.8.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   79:            blk.8.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   80:            blk.8.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   81:              blk.8.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   82:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   83:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   84:              blk.9.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   85:              blk.9.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   86:              blk.9.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   87:         blk.9.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   88:            blk.9.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   89:            blk.9.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   90:              blk.9.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   91:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   92:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   93:             blk.10.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   94:             blk.10.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   95:             blk.10.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   96:        blk.10.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   97:           blk.10.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor   98:           blk.10.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   99:             blk.10.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  100:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  101:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  102:             blk.11.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  103:             blk.11.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  104:             blk.11.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  105:        blk.11.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  106:           blk.11.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  107:           blk.11.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  108:             blk.11.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  109:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  110:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  111:             blk.12.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  112:             blk.12.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  113:             blk.12.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  114:        blk.12.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  115:           blk.12.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  116:           blk.12.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  117:             blk.12.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  118:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  119:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  120:             blk.13.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  121:             blk.13.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  122:             blk.13.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  123:        blk.13.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  124:           blk.13.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  125:           blk.13.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  126:             blk.13.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  127:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  128:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  129:             blk.14.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  130:             blk.14.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  131:             blk.14.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  132:        blk.14.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  133:           blk.14.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  134:           blk.14.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  135:             blk.14.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  136:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  137:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  138:             blk.15.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  139:             blk.15.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  140:             blk.15.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  141:        blk.15.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  142:           blk.15.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  143:           blk.15.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  144:             blk.15.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  145:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  146:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  147:             blk.16.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  148:             blk.16.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  149:             blk.16.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  150:        blk.16.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  151:           blk.16.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  152:           blk.16.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  153:             blk.16.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  154:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  155:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  156:             blk.17.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  157:             blk.17.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  158:             blk.17.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  159:        blk.17.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  160:           blk.17.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  161:           blk.17.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  162:             blk.17.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  163:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  164:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  165:             blk.18.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  166:             blk.18.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  167:             blk.18.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  168:        blk.18.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  169:           blk.18.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  170:           blk.18.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  171:             blk.18.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  172:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  173:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  174:             blk.19.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  175:             blk.19.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  176:             blk.19.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  177:        blk.19.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  178:           blk.19.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  179:           blk.19.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  180:             blk.19.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  181:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  182:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  183:             blk.20.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  184:             blk.20.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  185:             blk.20.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  186:        blk.20.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  187:           blk.20.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  188:           blk.20.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  189:             blk.20.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  190:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  191:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  192:             blk.21.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  193:             blk.21.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  194:             blk.21.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  195:        blk.21.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  196:           blk.21.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  197:           blk.21.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  198:             blk.21.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  199:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  200:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  201:             blk.22.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  202:             blk.22.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  203:             blk.22.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  204:        blk.22.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  205:           blk.22.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  206:           blk.22.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  207:             blk.22.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  208:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  209:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  210:             blk.23.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  211:             blk.23.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  212:             blk.23.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  213:        blk.23.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  214:           blk.23.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  215:           blk.23.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  216:             blk.23.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  217:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  218:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  219:             blk.24.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  220:             blk.24.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  221:             blk.24.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  222:        blk.24.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  223:           blk.24.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  224:           blk.24.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  225:             blk.24.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  226:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  227:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  228:             blk.25.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  229:             blk.25.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  230:             blk.25.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  231:        blk.25.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  232:           blk.25.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  233:           blk.25.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  234:             blk.25.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  235:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  236:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  237:             blk.26.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  238:             blk.26.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  239:             blk.26.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  240:        blk.26.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  241:           blk.26.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  242:           blk.26.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  243:             blk.26.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  244:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  245:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  246:             blk.27.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  247:             blk.27.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  248:             blk.27.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  249:        blk.27.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  250:           blk.27.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  251:           blk.27.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  252:             blk.27.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  253:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  254:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  255:             blk.28.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  256:             blk.28.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  257:             blk.28.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  258:        blk.28.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  259:           blk.28.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  260:           blk.28.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  261:             blk.28.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  262:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  263:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  264:             blk.29.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  265:             blk.29.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  266:             blk.29.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  267:        blk.29.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  268:           blk.29.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  269:           blk.29.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  270:             blk.29.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  271:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  272:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  273:             blk.30.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  274:             blk.30.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  275:             blk.30.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  276:        blk.30.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  277:           blk.30.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  278:           blk.30.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  279:             blk.30.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  280:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  281:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  282:             blk.31.attn_q.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  283:             blk.31.attn_k.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  284:             blk.31.attn_v.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  285:        blk.31.attn_output.weight q4_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  286:           blk.31.ffn_gate.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  287:           blk.31.ffn_down.weight q4_0     [ 11008,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  288:             blk.31.ffn_up.weight q4_0     [  4096, 11008,     1,     1 ]\n",
            "llama_model_loader: - tensor  289:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  290:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - kv   0:                       general.architecture str     \n",
            "llama_model_loader: - kv   1:                               general.name str     \n",
            "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
            "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
            "llama_model_loader: - kv  10:                          general.file_type u32     \n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
            "llama_model_loader: - kv  15:               general.quantization_version u32     \n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 2048\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = mostly Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW) \n",
            "llm_load_print_meta: general.name   = llama\n",
            "llm_load_print_meta: BOS token = 1 '<s>'\n",
            "llm_load_print_meta: EOS token = 2 '</s>'\n",
            "llm_load_print_meta: UNK token = 0 '<unk>'\n",
            "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.11 MB\n",
            "llm_load_tensors: using CUDA for GPU acceleration\n",
            "llm_load_tensors: mem required  = 3647.97 MB\n",
            "llm_load_tensors: offloading 0 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 0/35 layers to GPU\n",
            "llm_load_tensors: VRAM used: 0.00 MB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_new_context_with_model: kv self size  =  256.00 MB\n",
            "llama_build_graph: non-view tensors processed: 740/740\n",
            "llama_new_context_with_model: compute buffer total size = 11.03 MB\n",
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
            "llama_new_context_with_model: VRAM scratch buffer: 4.41 MB\n",
            "llama_new_context_with_model: total VRAM used: 4.41 MB (model: 0.00 MB, context: 4.41 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AFGY1P6xLKrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Question: What is the capital of England??\n",
        "\"\"\"\n",
        "llm(prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhSDgAsawGZB",
        "outputId": "0478ba2a-e710-4301-e78c-be80710209b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: London is the capital of England."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    2100.48 ms\n",
            "llama_print_timings:      sample time =       4.67 ms /    11 runs   (    0.42 ms per token,  2353.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2100.00 ms /    12 tokens (  175.00 ms per token,     5.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2662.55 ms /    10 runs   (  266.26 ms per token,     3.76 tokens per second)\n",
            "llama_print_timings:       total time =    4816.79 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswer: London is the capital of England.'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Question: who is the king there?\n",
        "\"\"\"\n",
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sMzGRGvwaBj",
        "outputId": "7f4a2cb7-44d8-4291-cda5-18df9e2be442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: The King of Thailand is currently Maha Vajiralongkorn Bodindradebayavarangsi, also known as King Rama X. He ascended to the throne in 2016 upon the death of his father, King Bhumibol Adulyadej."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    2100.48 ms\n",
            "llama_print_timings:      sample time =      29.52 ms /    65 runs   (    0.45 ms per token,  2202.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1256.40 ms /     7 tokens (  179.49 ms per token,     5.57 tokens per second)\n",
            "llama_print_timings:        eval time =   16659.00 ms /    64 runs   (  260.30 ms per token,     3.84 tokens per second)\n",
            "llama_print_timings:       total time =   18239.12 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAnswer: The King of Thailand is currently Maha Vajiralongkorn Bodindradebayavarangsi, also known as King Rama X. He ascended to the throne in 2016 upon the death of his father, King Bhumibol Adulyadej.'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Question: who will be next to throne after the queen?\n",
        "\"\"\"\n",
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANNBZoU8wfEQ",
        "outputId": "ab9a8f4f-3d27-4c7f-c258-87f3d53093f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The current line of succession to the British throne is as follows:\n",
            "\n",
            "1. Queen Elizabeth II\n",
            "2. Prince Charles, Prince of Wales (her eldest son)\n",
            "3. Prince William, Duke of Cambridge (her grandson and Prince Charles's eldest son)\n",
            "4. Prince George of Cambridge (Prince William and Catherine Middleton's eldest son)\n",
            "5. Princess Charlotte of Cambridge (Prince William and Catherine Middleton's second child and only daughter)\n",
            "6. Prince Louis of Cambridge (Prince William and Catherine Middleton's third child and second son)\n",
            "7. Prince Andrew, Duke of York (Queen Elizabeth II's second son)\n",
            "8. Princess Beatrice of York (Prince Andrew's eldest daughter)\n",
            "9. Princess Eugenie of York (Prince Andrew's youngest daughter)\n",
            "10. Viscount Severn (Princess Anne's elder son)\n",
            "\n",
            "So, after Queen Elizabeth II, the next in line to the throne would be Prince Charles, followed by his sons and then his grandchildren."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    2100.48 ms\n",
            "llama_print_timings:      sample time =      99.09 ms /   230 runs   (    0.43 ms per token,  2321.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1833.04 ms /    10 tokens (  183.30 ms per token,     5.46 tokens per second)\n",
            "llama_print_timings:        eval time =   62967.33 ms /   229 runs   (  274.97 ms per token,     3.64 tokens per second)\n",
            "llama_print_timings:       total time =   66012.17 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nThe current line of succession to the British throne is as follows:\\n\\n1. Queen Elizabeth II\\n2. Prince Charles, Prince of Wales (her eldest son)\\n3. Prince William, Duke of Cambridge (her grandson and Prince Charles's eldest son)\\n4. Prince George of Cambridge (Prince William and Catherine Middleton's eldest son)\\n5. Princess Charlotte of Cambridge (Prince William and Catherine Middleton's second child and only daughter)\\n6. Prince Louis of Cambridge (Prince William and Catherine Middleton's third child and second son)\\n7. Prince Andrew, Duke of York (Queen Elizabeth II's second son)\\n8. Princess Beatrice of York (Prince Andrew's eldest daughter)\\n9. Princess Eugenie of York (Prince Andrew's youngest daughter)\\n10. Viscount Severn (Princess Anne's elder son)\\n\\nSo, after Queen Elizabeth II, the next in line to the throne would be Prince Charles, followed by his sons and then his grandchildren.\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Question: as ans AI LLM model, when is your last training date?\n",
        "\"\"\"\n",
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuJJDo3WxE0-",
        "outputId": "e472e9c0-cbff-4a79-a9ee-8923ec7654ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " nobody knows the answer to that question.\n",
            "\n",
            "Because I'm just an AI assistant trained by Meta AI, I don't have a specific \"last training date\" in the classical sense. My training process is ongoing and continuous, as I learn from a vast corpus of text data and improve my language models over time.\n",
            "My training data includes a wide range of texts, including books, articles, and websites, which are constantly being updated and expanded to keep my knowledge up-to-date. This means that my understanding of language and my ability to generate responses are always evolving and improving.\n",
            "So, while I can't provide you with an exact date for when I was \"last trained,\" I can assure you that I am constantly learning and adapting to improve my language abilities."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    2100.48 ms\n",
            "llama_print_timings:      sample time =      79.86 ms /   171 runs   (    0.47 ms per token,  2141.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2898.41 ms /    16 tokens (  181.15 ms per token,     5.52 tokens per second)\n",
            "llama_print_timings:        eval time =   44636.88 ms /   170 runs   (  262.57 ms per token,     3.81 tokens per second)\n",
            "llama_print_timings:       total time =   48404.08 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' nobody knows the answer to that question.\\n\\nBecause I\\'m just an AI assistant trained by Meta AI, I don\\'t have a specific \"last training date\" in the classical sense. My training process is ongoing and continuous, as I learn from a vast corpus of text data and improve my language models over time.\\nMy training data includes a wide range of texts, including books, articles, and websites, which are constantly being updated and expanded to keep my knowledge up-to-date. This means that my understanding of language and my ability to generate responses are always evolving and improving.\\nSo, while I can\\'t provide you with an exact date for when I was \"last trained,\" I can assure you that I am constantly learning and adapting to improve my language abilities.'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}