{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfuc2OnM76kcrLNBd4CvD4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ellen-Gu/quantity-analysis/blob/main/tf_spped_test_glab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This speed test using google colab free service (denote as G).\n",
        "Other tests are done on personal laptop, one medium size public cloud (with GPU, free service, denote as M), and one small public cloud (with GPU, paid service, denote as S).\n",
        "\n",
        "The testing code is from learning modules in google tensorflow docker image, the classification jupyter notebook. My own laptop was bought just several months earlier than the cut-off date. After that date the precision series' GPU support tensorflow 2.0 and above. Before that only tensorflow 1.X is supported. I installed tensorRT into the docker image but was very disappointed to find out that my hardware is just a little bit older than what tensorflow 2.X needed. The tesorflow 1.X codes are no longer well compatiable into tensorflow 2.X. Fortunately there are many GPU capable cloud services available outside, and tensorRT capable codes are not too far away from usual ones. At least my own laptop is merely ok for learning purpose.\n",
        "\n",
        "One interesting point is that google tensorflow image (2.X) does not include the tensorRT from nvidia. and there is no driver from nvida can fit into the version of those used in goolge's image. If tensorRT is wanted (and openAI thinks it is a very important and \"must-have\" component for speeding up, without it the tensorflow can only run on CPU. Currently only nivida GPU and google's TPU are able to run tensorflow), one has to start from scratch and use cuda toolkit>12.0 (to get compatiable tensorRT from nvidia website). After tensorRT is installed, the image size may increase 20GB, that is a lot. Aside tensorRT, I guess goole's tensorflow image may be optimzied to cut off unnecessary or some optional packages so it can stay at small size. Google says tensorflow is only officially supported on ubuntu system, though one can try on other linux distributions.\n",
        "\n",
        "From the speed testing results, if for CPU computing, my own laptop (denote as P) and the medium size public cloud (at highest speed as to free service) are with similar speed. that is, $P ≈ M$.\n",
        "\n",
        "* CPU: $M ≈ P$, $M > S$, for spark, $M (8-threads) ≈ 1.3X \\space P(4 -threads) $, $P=2X  \\space G$, there is nearly no speed improvement in G's spark running.\n",
        "* GPU: $M (GPU) ≈ 2X \\space M(cpu) ≈ 2X  \\space P(cpu)$, $S(GPU)=3X \\space P(cpu)$ , and it is verified that $M$ has tensorRT installed and ready to be used. In another testing with more complex images, M's GPU classification codes can still finish in several seconds, while tensorflow 2.13 running on my laptop (can only use CPU) needs to take 1.5 hr to finish.\n",
        "* TPU: G only, G(cpu) seems faster than its GPU and TPU (seems contradictary to general unstandings). Though no much speed imporovement, G is the only one which is available for testing TPU.\n",
        "\n",
        "( $l(aX)r$ means that $l$ is $ax $ faster than $r$ )\n"
      ],
      "metadata": {
        "id": "1VNxi_FGpdqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ###  Run tensorflow with **CPU**"
      ],
      "metadata": {
        "id": "mDdmstYtoFI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpPsbcZVl5fR",
        "outputId": "6b6faa35-4d7f-41db-947c-186d59a48ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4988 - accuracy: 0.8243\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3729 - accuracy: 0.8650\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3357 - accuracy: 0.8775\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3132 - accuracy: 0.8852\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2951 - accuracy: 0.8914\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2810 - accuracy: 0.8971\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2686 - accuracy: 0.9004\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2586 - accuracy: 0.9046\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2482 - accuracy: 0.9073\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2393 - accuracy: 0.9108\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(test_images)\n",
        "\n",
        "predictions[0]\n",
        "np.argmax(predictions[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### Run tensorflow with **GPU**"
      ],
      "metadata": {
        "id": "SYSDo8Iaop97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(test_images)\n",
        "\n",
        "predictions[0]\n",
        "np.argmax(predictions[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etiino-3moY4",
        "outputId": "cbf524f5-a4bb-4e3a-8b61-2b7c8746c695"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 14s 4ms/step - loss: 0.4986 - accuracy: 0.8243\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3731 - accuracy: 0.8653\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3336 - accuracy: 0.8791\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3110 - accuracy: 0.8856\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2937 - accuracy: 0.8921\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2791 - accuracy: 0.8973\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2657 - accuracy: 0.9014\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2537 - accuracy: 0.9049\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2458 - accuracy: 0.9087\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2353 - accuracy: 0.9118\n",
            "313/313 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### Run tensorflow with **TPU**"
      ],
      "metadata": {
        "id": "YGTUd4IXo1eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(test_images)\n",
        "\n",
        "predictions[0]\n",
        "np.argmax(predictions[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSE9BAalnHKY",
        "outputId": "78d0af6d-21de-4143-bc50-e9b1e4a226f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 1s 28us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.5008 - accuracy: 0.8230\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3793 - accuracy: 0.8634\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3406 - accuracy: 0.8762\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3162 - accuracy: 0.8844\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2956 - accuracy: 0.8912\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2810 - accuracy: 0.8957\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2675 - accuracy: 0.9008\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2562 - accuracy: 0.9045\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2469 - accuracy: 0.9082\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2370 - accuracy: 0.9111\n",
            "313/313 [==============================] - 2s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}